{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9kV9W7TGy1y8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "outputId": "3dedb98d-8ffe-42cc-c29c-d165adeae158"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matplotlib version: 3.7.1\n",
            "numpy version: 1.26.4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PackageNotFoundError",
          "evalue": "No package metadata was found for tiktoken",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPackageNotFoundError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2db1a45dbd9e>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m        ]\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpkgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{p} version: {version(p)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mversion\u001b[0;34m(distribution_name)\u001b[0m\n\u001b[1;32m    994\u001b[0m         \u001b[0;34m\"Version\"\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m     \"\"\"\n\u001b[0;32m--> 996\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mdistribution\u001b[0;34m(distribution_name)\u001b[0m\n\u001b[1;32m    967\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDistribution\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mor\u001b[0m \u001b[0msubclass\u001b[0m \u001b[0mthereof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m     \"\"\"\n\u001b[0;32m--> 969\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfrom_name\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    546\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPackageNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPackageNotFoundError\u001b[0m: No package metadata was found for tiktoken",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "pkgs = [\"matplotlib\",\n",
        "        \"numpy\",\n",
        "        \"tiktoken\",\n",
        "        \"torch\",\n",
        "        \"tensorflow\", # For OpenAI's pretrained weights\n",
        "        \"pandas\"      # Dataset loading\n",
        "       ]\n",
        "for p in pkgs:\n",
        "    print(f\"{p} version: {version(p)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3o1KR-aLUaH",
        "outputId": "61123d31-375b-4156-9c9f-9d5533a65bdd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "import zipfile\n",
        "\n",
        "import os\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "\n",
        "\n",
        "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
        "  if data_file_path.exists():\n",
        "    print(f\"{data_file_path} already exists. Skipping download and extraction\")\n",
        "    return\n",
        "  with urllib.request.urlopen(url) as response:\n",
        "    with open(zip_path, 'wb') as out_file:\n",
        "      out_file.write(response.read())\n",
        "  with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(extracted_path)\n",
        "\n",
        "  original_file_path = Path(extracted_path) /\"SMSSpamCollection\"\n",
        "  os.rename(original_file_path, data_file_path)\n",
        "  print(f\"File downloaded and saved as {data_file_path}\")\n",
        "\n",
        "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKMx0ifwL7IL",
        "outputId": "dff07f4f-acd8-42a5-daf5-04f1b308b987"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded and saved as sms_spam_collection/SMSSpamCollection.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
        "df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "7RUmEIXWOtgc",
        "outputId": "7ac8701a-eac1-40ed-a232-7cbfc0a33096"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Label                                               Text\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568   ham               Will ü b going to esplanade fr home?\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...\n",
              "5570   ham  The guy did some bitching but I acted like i'd...\n",
              "5571   ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-461dbf94-994d-47fe-a657-824ce8cd4344\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-461dbf94-994d-47fe-a657-824ce8cd4344')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-461dbf94-994d-47fe-a657-824ce8cd4344 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-461dbf94-994d-47fe-a657-824ce8cd4344');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9a946c18-dc1c-4030-800d-d9094869d5e5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9a946c18-dc1c-4030-800d-d9094869d5e5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9a946c18-dc1c-4030-800d-d9094869d5e5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_91ae721e-a9ed-4707-98f8-11789a7026e5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_91ae721e-a9ed-4707-98f8-11789a7026e5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIlQw7WgPBbF",
        "outputId": "525c8b39-ef92-473d-e3a0-09cbc5572b19"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_balanced_dataset(df):\n",
        "\n",
        "    # Count the instances of \"spam\"\n",
        "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
        "\n",
        "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
        "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
        "\n",
        "    # Combine ham \"subset\" with \"spam\"\n",
        "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
        "\n",
        "    return balanced_df\n",
        "\n",
        "balanced_df = create_balanced_dataset(df)\n",
        "print(balanced_df[\"Label\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3GrEN_sPavs",
        "outputId": "02c4e676-6cf8-4cb2-abcc-9d97418cfec0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     747\n",
            "spam    747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_df['Label']  = balanced_df['Label'].map({'ham': 0, 'spam':1})"
      ],
      "metadata": {
        "id": "yV1Ae7T7QIaz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_split(df, train_frac, validation_frac):\n",
        "  df = df.sample(frac = 1, random_state = 123).reset_index(drop= True)\n",
        "\n",
        "  train_end = int(len(df) * train_frac)\n",
        "  validation_end =  train_end + int(len(df) * validation_frac)\n",
        "\n",
        "  train_df = df[:train_end]\n",
        "  validation_df =  df[train_end:validation_end]\n",
        "  test_df = df[validation_end:]\n",
        "\n",
        "  return train_df, validation_df, test_df\n",
        "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
        "\n",
        "\n",
        "train_df.to_csv(\"train.csv\", index = None)\n",
        "\n",
        "validation_df.to_csv('validation.csv', index = None)\n",
        "\n",
        "test_df.to_csv('test.csv', index = None)"
      ],
      "metadata": {
        "id": "4Z2_HRyyQgZO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating data loaders"
      ],
      "metadata": {
        "id": "MYj32Mr-RbYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special= {'<|endoftext|>'}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3SmjF0kQkK8",
        "outputId": "067c74b7-703a-4964-fb85-c708b6404d58"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The SpamDataset class below identifies the longest sequence in the training dataset and adds the padding token to the others to match that sequence length\n"
      ],
      "metadata": {
        "id": "q5yPd-7xR0vU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class SpamDataset(Dataset):\n",
        "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "\n",
        "        # Pre-tokenize texts\n",
        "        self.encoded_texts = [\n",
        "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
        "        ]\n",
        "\n",
        "        if max_length is None:\n",
        "            self.max_length = self._longest_encoded_length()\n",
        "        else:\n",
        "            self.max_length = max_length\n",
        "            # Truncate sequences if they are longer than max_length\n",
        "            self.encoded_texts = [\n",
        "                encoded_text[:self.max_length]\n",
        "                for encoded_text in self.encoded_texts\n",
        "            ]\n",
        "\n",
        "        # Pad sequences to the longest sequence\n",
        "        self.encoded_texts = [\n",
        "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
        "            for encoded_text in self.encoded_texts\n",
        "        ]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        encoded = self.encoded_texts[index]\n",
        "        label = self.data.iloc[index][\"Label\"]\n",
        "        return (\n",
        "            torch.tensor(encoded, dtype=torch.long),\n",
        "            torch.tensor(label, dtype=torch.long)\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _longest_encoded_length(self):\n",
        "        max_length = 0\n",
        "        for encoded_text in self.encoded_texts:\n",
        "            encoded_length = len(encoded_text)\n",
        "            if encoded_length > max_length:\n",
        "                max_length = encoded_length\n",
        "        return max_length\n"
      ],
      "metadata": {
        "id": "Q7iubzVgRtvD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SpamDataset(\n",
        "    csv_file=\"train.csv\",\n",
        "    max_length=None,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "print(train_dataset.max_length)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yznr0ZPfYl_0",
        "outputId": "d4599c34-26e5-4089-b2eb-0ab0385a622e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that validation and test set samples that are longer than the longest training example are being truncated via encoded_text[:self.max_length] in the SpamDataset code\n",
        "This behavior is entirely optional, and it would also work well if we set max_length=None in both the validation and test set cases\n"
      ],
      "metadata": {
        "id": "Md6YvfPfY1XD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = SpamDataset(\n",
        "    csv_file = 'validation.csv',\n",
        "    max_length = train_dataset.max_length,\n",
        "    tokenizer = tokenizer\n",
        ")\n",
        "\n",
        "test_dataset = SpamDataset(\n",
        "    csv_file = 'test.csv',\n",
        "    max_length = train_dataset.max_length,\n",
        "    tokenizer = tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "Wklzz7X1Yyhw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")\n"
      ],
      "metadata": {
        "id": "foHvtNO2ZJzb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a verification step, we iterate through the data loaders and ensure that the batches contain 8 training examples each, where each training example consists of 120 tokens\n"
      ],
      "metadata": {
        "id": "oP9WWIruhbFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('train laoder:' )\n",
        "for input_batch, target_batch in train_loader:\n",
        "  pass\n",
        "print(\"input batch dimensions:\", input_batch.shape)\n",
        "print(\"label batch dimensions\", target_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRZfHgdehZU_",
        "outputId": "50daecb0-cb7c-4d53-8989-97a4ee05295c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train laoder:\n",
            "input batch dimensions: torch.Size([8, 120])\n",
            "label batch dimensions torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, let's print the total number of batches in each dataset\n"
      ],
      "metadata": {
        "id": "sJMtnMn2uEwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{len(train_loader)} training batches\")\n",
        "print(f\"{len(val_loader)} validation batches\")\n",
        "print(f\"{len(test_loader)} test batches\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEfeLS6shqc5",
        "outputId": "c97c5a61-d9c0-4954-a11f-b7595267b631"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130 training batches\n",
            "19 validation batches\n",
            "38 test batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing a model with pretrained weights"
      ],
      "metadata": {
        "id": "YImmOARYuSSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "INPUT_PROMPT = \"Every effort moves\"\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
        "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
        "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
        "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "VYK7porauShT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt_download import download_and_load_gpt2\n",
        "from previous_chapters import GPTModel, load_weights_into_gpt\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "640VzaZRubJy",
        "outputId": "d78e932d-53d6-4e2c-cd0d-5f2e385abebc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 35.9kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 3.18MiB/s]\n",
            "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 59.3kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:15<00:00, 32.8MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 3.44MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 1.80MiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 2.19MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from previous_chapters import (\n",
        "    generate_text_simple,\n",
        "    text_to_token_ids,\n",
        "    token_ids_to_text\n",
        ")\n",
        "\n",
        "\n",
        "text_1 = \"Every effort moves you\"\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_1, tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(token_ids_to_text(token_ids, tokenizer))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SVmjSw5wrv0",
        "outputId": "cae266cc-a003-4245-e486-e218fa8314a7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Every effort moves you forward.\n",
            "\n",
            "The first step is to understand the importance of your work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we finetune the model as a classifier, let's see if the model can perhaps already classify spam messages via prompting\n"
      ],
      "metadata": {
        "id": "F5hBPzQAxtqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = (\n",
        "        \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
        "    \" 'You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
        ")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model = model,\n",
        "    idx=text_to_token_ids(text_2, tokenizer),\n",
        "    max_new_tokens =23,\n",
        "    context_size = BASE_CONFIG['context_length']\n",
        ")\n",
        "\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpuWovdYxnrC",
        "outputId": "1df256e6-beaf-4875-8974-2b991c2fdf9f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
            "\n",
            "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding a classification head"
      ],
      "metadata": {
        "id": "P9AGo4sFyTLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4tfKoqsyQO9",
        "outputId": "c47fccd8-6def-4031-a756-d5a5cc1bfbcb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPTModel(\n",
            "  (tok_emb): Embedding(50257, 768)\n",
            "  (pos_emb): Embedding(1024, 768)\n",
            "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "  param.requires_grad = False"
      ],
      "metadata": {
        "id": "ZNmQ2TGkyXWJ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we replace the output layer (model.out_head), which originally maps the layer inputs to 50,257 dimensions (the size of the vocabulary)\n",
        "Since we finetune the model for binary classification (predicting 2 classes, \"spam\" and \"not spam\"), we can replace the output layer as shown below, which will be trainable by default\n",
        "Note that we use BASE_CONFIG[\"emb_dim\"] (which is equal to 768 in the \"gpt2-small (124M)\" model) to keep the code below more general\n"
      ],
      "metadata": {
        "id": "rcwITP9xy66N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "num_classes = 2\n",
        "\n",
        "model.out_head =  torch.nn.Linear(in_features = BASE_CONFIG['emb_dim'], out_features = num_classes)"
      ],
      "metadata": {
        "id": "LOQMDJz8y1jI"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Technically, it's sufficient to only train the output layer\n",
        "However, as I found in Finetuning Large Language Models, experiments show that finetuning additional layers can noticeably improve the performance\n",
        "So, we are also making the last transformer block and the final LayerNorm module connecting the last transformer block to the output layer trainable\n"
      ],
      "metadata": {
        "id": "mY9cCJ5RzJkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.trf_blocks[-1].parameters():\n",
        "  param.requires_grad = True\n",
        "for pram in model.final_norm.parameters():\n",
        "  param.requires_grad = True"
      ],
      "metadata": {
        "id": "L3ZgXJuGzHOS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer.encode(\"Do you have time\")\n",
        "\n",
        "\n",
        "inputs = torch.tensor(inputs).unsqueeze(0)\n",
        "\n",
        "print(\"Inputs: \", inputs)\n",
        "print(\"Inputs dimenstions: \", inputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4-UYxqw0Z0z",
        "outputId": "d6e8f4ce-adb4-4f6e-90af-23235f1d5add"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:  tensor([[5211,  345,  423,  640]])\n",
            "Inputs dimenstions:  torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  outputs = model(inputs)\n",
        "\n",
        "print(\"outputs: \\n\", outputs)\n",
        "\n",
        "print(\"Outputs dimenstions\", outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFxHfa7E0pEo",
        "outputId": "33302af9-f126-41f2-c591-61eeafbe3c35"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "outputs: \n",
            " tensor([[[-1.5854,  0.9904],\n",
            "         [-3.7235,  7.4548],\n",
            "         [-2.2661,  6.6049],\n",
            "         [-3.5983,  3.9902]]])\n",
            "Outputs dimenstions torch.Size([1, 4, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Lastn output token: \" , outputs[:, -1, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAqTstiR05ib",
        "outputId": "9d28e804-7ef9-41c4-9198-ff277f02ccf3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lastn output token:  tensor([[-3.5983,  3.9902]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Last output token:\", outputs[:, -1, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjbtZXa51Rvp",
        "outputId": "8f7d47e6-7bd2-4463-a848-c68694d3cb22"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last output token: tensor([[-3.5983,  3.9902]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
        "label = torch.argmax(probas)\n",
        "print(\"Class label:\", label.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFbVOmWe1apb",
        "outputId": "05360032-03b5-405b-d87d-32626736cabc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = outputs[:, -1, :]\n",
        "\n",
        "label = torch.argmax(logits)\n",
        "\n",
        "print(\"Class Label\",label.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YZlVWZM1qVH",
        "outputId": "9cac5ce1-a6fd-4c4a-aa10-91d20a2d09e6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Label 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's apply the function to calculate the classification accuracies for the different datasets:\n"
      ],
      "metadata": {
        "id": "xCuQ-cDH3vSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
        "    model.eval()\n",
        "    correct_predictions, num_examples = 0, 0\n",
        "\n",
        "    if num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
        "            predicted_labels = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            num_examples += predicted_labels.shape[0]\n",
        "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
        "        else:\n",
        "            break\n",
        "    return correct_predictions / num_examples\n"
      ],
      "metadata": {
        "id": "rxXH4lTh3tcJ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "GuDeKWPz3qM2"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
        "\n",
        "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
        "\n",
        "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ulg_ZhR3eu0",
        "outputId": "cd5c7d88-09aa-4d56-c6f5-c26f72861a05"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 46.25%\n",
            "Validation accuracy: 45.00%\n",
            "Test accuracy: 48.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "  input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "  logits = model(input_batch)[:, -1, :]\n",
        "  loss = torch.nn.functional.cross_entropy(logits,target_batch)\n",
        "  return loss\n",
        ""
      ],
      "metadata": {
        "id": "oYzb9XkP3j5Q"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_loader(data_loader, model, device, num_batches = None):\n",
        "  total_loss = 0.\n",
        "  if len(data_loader) == 0:\n",
        "    return float(\"nan\")\n",
        "  elif num_batches is None:\n",
        "    num_batches = len(data_loader)\n",
        "  else:\n",
        "    num_batches = min(num_batches, len(data_loader))\n",
        "  for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "    if i < num_batches:\n",
        "      loss =  calc_loss_batch(input_batch, target_batch, model, device)\n",
        "      total_loss += loss.item()\n",
        "  return total_loss/ num_batches"
      ],
      "metadata": {
        "id": "NrUosgRZ4pKE"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the calc_closs_loader, we compute the initial training, validation, and test set losses before we start training\n"
      ],
      "metadata": {
        "id": "tMirxkHe5bYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  train_loss  = calc_loss_loader(train_loader, model, device, num_batches = 5)\n",
        "  val_loss = calc_loss_loader(val_loader, model, device, num_batches = 5)\n",
        "  test_loss = calc_loss_loader(test_loader, model, device, num_batches = 4)"
      ],
      "metadata": {
        "id": "F0JjKHk75YbJ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"training loss: {train_loss: .3f}\")\n",
        "print(f\"validation loss {val_loss: .3f}\")\n",
        "print(f\"Test loss: {test_loss: .3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBTs2auM50mY",
        "outputId": "1d19c9ad-3970-4225-c9c3-c8b5a0706aae"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss:  2.453\n",
            "validation loss  2.583\n",
            "Test loss:  2.424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Overall the same as `train_model_simple` in chapter 5\n",
        "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                            eval_freq, eval_iter):\n",
        "    # Initialize lists to track losses and examples seen\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "    examples_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Calculate accuracy after each epoch\n",
        "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
        "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "        train_accs.append(train_accuracy)\n",
        "        val_accs.append(val_accuracy)\n",
        "\n",
        "    return train_losses, val_losses, train_accs, val_accs, examples_seen\n"
      ],
      "metadata": {
        "id": "HaCsY5-76PpG"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches = eval_iter)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches = eval_iter)\n",
        "  model.train()\n",
        "  return train_loss, val_loss"
      ],
      "metadata": {
        "id": "mkVCF5ub8hxV"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = 5e-5, weight_decay = 0.1)\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "train_losses, val_losses, train_accs , val_accs, examples_seen  =  train_classifier_simple(\n",
        "    model, train_loader, val_loader, optimizer, device, num_epochs = num_epochs, eval_freq = 50, eval_iter = 5,\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "\n",
        "execution_time_minutes = (end_time -start_time) /60\n",
        "\n",
        "print(f\"Training Completed in {execution_time_minutes:. 2f} minutes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "NIGJBdx987Cr",
        "outputId": "b572970b-6d4b-4672-a216-297aba142ed9"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 2.154, Val loss 2.392\n",
            "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
            "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
            "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
            "Ep 2 (Step 000150): Train loss 0.560, Val loss 0.488\n",
            "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.396\n",
            "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
            "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
            "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.321\n",
            "Ep 3 (Step 000350): Train loss 0.343, Val loss 0.311\n",
            "Training accuracy: 87.50% | Validation accuracy: 87.50%\n",
            "Ep 4 (Step 000400): Train loss 0.166, Val loss 0.235\n",
            "Ep 4 (Step 000450): Train loss 0.166, Val loss 0.145\n",
            "Ep 4 (Step 000500): Train loss 0.227, Val loss 0.147\n",
            "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
            "Ep 5 (Step 000550): Train loss 0.208, Val loss 0.150\n",
            "Ep 5 (Step 000600): Train loss 0.091, Val loss 0.077\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Format specifier missing precision",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-9cb960d1dff9>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mexecution_time_minutes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training Completed in {execution_time_minutes:. 2f} minutes.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: Format specifier missing precision"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_values(epochs_seen, examples_seen, train_values, val_values, label =  \"loss\"):\n",
        "  fig,ax1  = plt.subplots(figsize =(5,3))\n",
        "\n",
        "  ax1.plot(epochs_seen, train_values, label = f\"Training {label}\")\n",
        "  ax1.plot(epochs_seen, val_values, linestyle= \"-.\",  label = f'validation {label}')\n",
        "  ax1.set_xlabel(\"Epochs\")\n",
        "  ax1.set_ylabel(label.captitalize())\n",
        "  ax1.legend()\n",
        "\n",
        "  ax2  =  ax1.twiny()\n",
        "  ax2.plot(examples_seen, train_values, alpha = 0)\n",
        "  ax2.set_xlabel(\"Exmaples seen\")\n",
        "\n",
        "  fig.tight_layout()\n",
        "  plt.savefig(f\"{label}-plot.pd\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "fA0Jmq7d_Gra"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "7po_OdRjCAUm",
        "outputId": "3cafed05-686e-4986-acbd-f760323606f4"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'captitalize'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-1a46100ef649>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mexamples_seen_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples_seen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplot_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples_seen_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-60-31da38385727>\u001b[0m in \u001b[0;36mplot_values\u001b[0;34m(epochs_seen, examples_seen, train_values, val_values, label)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_seen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"-.\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'validation {label}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptitalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'captitalize'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
        "\n",
        "examples_seen_tensor  = torch.linspace(0, examples_seen, len(train_accs))\n",
        "\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label =\"Accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "fek_URyJCUfS",
        "outputId": "96418b5c-356d-4c80-efb2-f342f1d25b5d"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'captitalize'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-7709fee31318>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplot_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples_seen_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\"Accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-60-31da38385727>\u001b[0m in \u001b[0;36mplot_values\u001b[0;34m(epochs_seen, examples_seen, train_values, val_values, label)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_seen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"-.\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'validation {label}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptitalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'captitalize'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GuUAT1gCqyg",
        "outputId": "af88ea2e-5e35-4810-b476-aa613bfe7ed6"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 96.73%\n",
            "Validation accuracy: 97.32%\n",
            "Test accuracy: 96.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "finetuned GPT model in action"
      ],
      "metadata": {
        "id": "T7tklyJqM1lC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
        "    model.eval()\n",
        "\n",
        "    # Prepare inputs to the model\n",
        "    input_ids = tokenizer.encode(text)\n",
        "    supported_context_length = model.pos_emb.weight.shape[0]\n",
        "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
        "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
        "\n",
        "    # Truncate sequences if they too long\n",
        "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
        "\n",
        "    # Pad sequences to the longest sequence\n",
        "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
        "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
        "\n",
        "    # Model inference\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
        "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "    # Return the classified result\n",
        "    return \"spam\" if predicted_label == 1 else \"not spam\"\n"
      ],
      "metadata": {
        "id": "NOSFzUFfRoV2"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = (\n",
        "        \"You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.\"\n",
        ")\n",
        "\n",
        "print(classify_review(\n",
        "    text_1, model, tokenizer, device, max_length = train_dataset.max_length\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ej5qMiXEN5Gj",
        "outputId": "2f3b1420-e2a1-47e9-ce4f-0bc50999bf77"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = (\n",
        "        \"Hey, just wanted to check if we're still on\"\n",
        "    \" for dinner tonight? Let me know!\"\n",
        "\n",
        ")\n",
        "\n",
        "print(classify_review(\n",
        "    text_2, model, tokenizer, device, max_length= train_dataset.max_length\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kesxkhSxOHH7",
        "outputId": "1e883754-74d6-40f5-fd9f-0f78c1cffbcf"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"review_classfier.pth\")"
      ],
      "metadata": {
        "id": "5cFJTF1uOYUg"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_state_dict = torch.load(\"review_classfier.pth\", map_location = device, weights_only= True)\n",
        "model.load_state_dict(model_state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qsuig43aOeZR",
        "outputId": "3cf7495f-7903-4af8-b703-1d46dc7c2eaa"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.copy(\"/content/review_classfier.pth\",\"/content/drive/MyDrive/\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SuDpR1gTSSoM",
        "outputId": "0718c49b-ec4e-4fdc-ccdd-db8a8549cd3a"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/review_classfier.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Vwk2ZxpShU3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}